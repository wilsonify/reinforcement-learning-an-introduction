;-*- Package: (cl-user) -*-;;; The classic random walk, solved by TD methods.;;; This version is for 1) online n-step methods, 2) conventional online TD(lambda) ;;; with accumulating traces, 3) the online lambda-return algorithm, and;;; 4) the simplified version of 3 with just dutch traces;;; The code and calls for some of the figures in the RL text is given at the very end.(defvar NN)                             ; the n of nstep(defvar n 19)                           ; the number of nonterminal states(defvar w)                              ; the vector of weights = predictions(defvar e)                              ; the eligibility trace(defvar lambda .9)                      ; trace decay parameter(defvar alpha 0.1)                      ; learning-rate parameter(defvar standard-walks nil)             ; list of standard walks(defvar targets)                        ; the correct predictions(defvar right-outcome 1.0)(defvar left-outcome -1.0)(defvar initial-w 0.0)(defvar Vold)(defvar deltaV)(defun setup (num-runs num-walks)  (setq w (make-array n))  (setq e (make-array n))  (setq standard-walks (standard-walks num-runs num-walks))  (length standard-walks))(defun init ()  (loop for i below n do (setf (aref w i) initial-w))  (setq Vold 0)  (setq targets         (loop for i below n collect               (+ (* (- right-outcome left-outcome)                     (/ (+ i 1) (+ n 1)))                 left-outcome))))(defun init-traces ()  (loop for i below n do (setf (aref e i) 0)))(defun learn-fv (x target)  (incf (aref w x) (* alpha (- target (aref w x)))))(defun learn-TDlambda (x target)  (loop for i below n do (setf (aref e i) (* lambda (aref e i))))  (incf (aref e x) 1)                                    ;accumulate  ;(setf (aref e x) (+ 1 (* (- 1 alpha) (aref e x))))     ;dutch  ;(setf (aref e x) 1)                                    ;replace  (loop for i below n     with error = (- target (aref w x))    do (incf (aref w i) (* alpha error (aref e i)))))(defun learn-true-online (x target)  (setq deltaV (- (aref w x) Vold))  (setq Vold target)  (setf (aref e x) (+ 1 (* (- 1 alpha) (aref e x))))  (loop with delta+deltaV = (+ (- target (aref w x)) deltaV)    for i below n do    (incf (aref w i) (* alpha delta+deltaV (aref e i)))    (setf (aref e i) (* lambda (aref e i))))  (decf (aref w x) (* alpha deltaV)))(defun learn-dutch-TDlambda (x target)  (setf (aref e x) (+ 1 (* (- 1 alpha) (aref e x))))  (loop with alpha-delta = (* alpha (- target (aref w x)))    for i below n do    (incf (aref w i) (* alpha-delta (aref e i)))    (setf (aref e i) (* lambda (aref e i)))))(defun process-walk-TDlambda (walk)  (destructuring-bind (outcome states) walk    (init-traces)    (loop for s1 in states          for s2 in (rest states)          do (learn-TDlambda s1 (aref w s2)))    (learn-TDlambda (first (last states)) outcome)))(defun process-walk-nstep (walk)  (destructuring-bind (outcome states) walk   (loop for s1 in states          for rest on states          do (learn-fv s1 (if (>= NN (length rest))                         outcome                         (aref w (nth NN rest)))))))(defun process-walk-lambda-return (walk)  (destructuring-bind (outcome states) walk    (loop for s1 in states          for rest on states          for target = (+ (* (- 1 lambda)                             (loop for St+n in (cdr rest)                                   for ln = 1 then (* ln lambda)                                   sum (* ln (aref w St+n))))                          (* (expt lambda (length (cdr rest)))                             outcome))          do (learn-fv s1 target))))(defun process-walk-true-online (walk)  (destructuring-bind (outcome states) walk    (init-traces)    (loop for s1 in states          for s2 in (rest states)          do (learn-true-online s1 (aref w s2)))    (learn-true-online (first (last states)) outcome)))(defun process-walk-dutch-TDlambda (walk)  (destructuring-bind (outcome states) walk    (init-traces)    (loop for s1 in states          for s2 in (rest states)          do (learn-dutch-TDlambda s1 (aref w s2)))    (learn-dutch-TDlambda (first (last states)) outcome)))(defun standard-walks (num-sets-of-walks num-walks)  (loop repeat num-sets-of-walks         with random-state = (ut::copy-of-standard-random-state)        collect (loop repeat num-walks                      collect (random-walk n random-state))))(defun random-walk (n &optional (random-state *random-state*))  (loop with start-state = (truncate (/ n 2))        for x = start-state then (with-prob .5 (+ x 1) (- x 1) random-state)        while (AND (>= x 0) (< x n))        collect x into xs        finally (return (list (if (< x 0) left-outcome right-outcome) xs))))(defun residual-error ()  "Returns the residual RMSE between the current and correct predictions"  (rmse 0 (loop for w-i across w                for target-i in targets                collect (- w-i target-i))))(defun learning-curve-TDlambda (alpha-arg lambda-arg)  (setq alpha alpha-arg)  (setq lambda lambda-arg)  (multi-mean    (loop for walk-set in standard-walks         do (init)         collect (cons (residual-error)                       (loop for walk in walk-set                             do (process-walk-TDlambda walk)                             collect (residual-error))))))(defun learning-curve-nstep (alpha-arg NN-arg)  (setq alpha alpha-arg)  (setq NN NN-arg)  (multi-mean    (loop for walk-set in standard-walks         do (init)         collect (cons (residual-error)                       (loop for walk in walk-set                             do (process-walk-nstep walk)                             collect (residual-error))))))(defun learning-curve-lambda-return (alpha-arg lambda-arg)  (setq alpha alpha-arg)  (setq lambda lambda-arg)  (multi-mean    (loop for walk-set in standard-walks         do (init)         collect (cons (residual-error)                       (loop for walk in walk-set                             do (process-walk-lambda-return walk)                             collect (residual-error))))))(defun learning-curve-true-online (alpha-arg lambda-arg)  (setq alpha alpha-arg)  (setq lambda lambda-arg)  (multi-mean    (loop for walk-set in standard-walks         do (init)         collect (cons (residual-error)                       (loop for walk in walk-set                             do (process-walk-true-online walk)                             collect (residual-error))))))(defun learning-curve-dutch-TDlambda (alpha-arg lambda-arg)  (setq alpha alpha-arg)  (setq lambda lambda-arg)  (multi-mean    (loop for walk-set in standard-walks         do (init)         collect (cons (residual-error)                       (loop for walk in walk-set                             do (process-walk-dutch-TDlambda walk)                             collect (residual-error))))))(defun online-TDlambda ()  "summary results as fn of alpha, for various lambda"  (graph (loop for lambda in '(0 .4 .8 .9 .95 .975 .99 1) collect           (cons (progn (init) (list 0 (residual-error)))                 (loop for alog from -5 to 0 by 0.1                   for alpha = (exp alog)                   for error = (mean (rest (learning-curve-TDlambda alpha lambda)))                   while (< error 10)                   collect (list alpha error)))))  (y-tick-marks .25 .3 .35 .4 .45 .5 .55)  (x-tick-marks 0 .2 .4 .6 .8 1)  (y-graph-limits .25 .55)  (x-graph-limits 0 1))  (defun online-nstep ()  "summary results as fn of alpha, for various n"  (graph (loop for nstep = 1 then (* nstep 2) while (< nstep 1000) collect           (cons (progn (init) (list 0 (residual-error)))                 (loop for alog from -5 to 0 by 0.1                   for alpha = (exp alog)                   for error = (mean (rest (learning-curve-nstep alpha nstep)))                   while (< error 10)                   collect (list alpha error)))))   (y-tick-marks .25 .3 .35 .4 .45 .5 .55)  (x-tick-marks 0 .2 .4 .6 .8 1)  (y-graph-limits .25 .55)  (x-graph-limits 0 1))  (defun online-lambda-return ()  "summary results as fn of alpha, for various lambda"  (graph (loop for lambda in '(0 .4 .8 .9 .95 .975 .99 1) collect           (cons (progn (init) (list 0 (residual-error)))                 (loop for alog from -5 to 0 by 0.1                   for alpha = (exp alog)                   for error = (mean (rest (learning-curve-lambda-return alpha lambda)))                   while (< error 10)                   collect (list alpha error)))))  (y-tick-marks .25 .3 .35 .4 .45 .5 .55)  (x-tick-marks 0 .2 .4 .6 .8 1)  (y-graph-limits .25 .55)  (x-graph-limits 0 1))  (defun true-online-TDlambda ()  "summary results as fn of alpha, for various lambda"  (graph (loop for lambda in '(0 .4 .8 .9 .95 .975 .99 1) collect           (cons (progn (init) (list 0 (residual-error)))                 (loop for alog from -5 to 0 by 0.1                   for alpha = (exp alog)                   for error = (mean (rest (learning-curve-true-online alpha lambda)))                   while (< error 10)                   collect (list alpha error)))))  (y-tick-marks .25 .3 .35 .4 .45 .5 .55)  (x-tick-marks 0 .2 .4 .6 .8 1)  (y-graph-limits .25 .55)  (x-graph-limits 0 1))  (defun dutch-TDlambda ()  "summary results as fn of alpha, for various lambda"  (graph (loop for lambda in '(0 .4 .8 .9 .95 .975 .99 1) collect           (cons (progn (init) (list 0 (residual-error)))                 (loop for alog from -5 to 0 by 0.1                   for alpha = (exp alog)                   for error = (mean (rest (learning-curve-dutch-TDlambda alpha lambda)))                   while (< error 10)                   collect (list alpha error)))))  (y-tick-marks .25 .3 .35 .4 .45 .5 .55)  (x-tick-marks 0 .2 .4 .6 .8 1)  (y-graph-limits .25 .55)  (x-graph-limits 0 1))  (defun compare-algs ()  (graph '((0 .25)))  (loop for lambda in '(.71) do    (graph+ (cons (progn (init) (list 0 (residual-error)))                  (loop for alog from -5 to 0 by 0.01                    for alpha = (exp alog)                    for error = (mean (rest (learning-curve-true-online alpha .73)))                    while (< error 10)                    collect (list alpha error))) :red)    (graph+ (cons (progn (init) (list 0 (residual-error)))                  (loop for alog from -5 to 0 by 0.01                    for alpha = (exp alog)                    for error = (mean (rest (learning-curve-TDlambda alpha .7)))                    while (< error 10)                    collect (list alpha error))) :green)    (graph+ (cons (progn (init) (list 0 (residual-error)))                  (loop for alog from -5 to 0 by 0.01                    for alpha = (exp alog)                    for error = (mean (rest (learning-curve-dutch-TDlambda alpha .73)))                    while (< error 10)                    collect (list alpha error))) :black)    (graph+ (cons (progn (init) (list 0 (residual-error)))                  (loop for alog from -5 to 0 by 0.01                    for alpha = (exp alog)                    for error = (mean (rest (learning-curve-lambda-return alpha .71)))                    while (< error 10)                    collect (list alpha error))) :blue)))#|(setq data nil)(loop for f in '(learning-curve-true-online learning-curve-TDlambda learning-curve-lambda-return) collect(loop for f in '(learning-curve-TDlambda) collect  (loop for lambda from .7 to .9 by 0.01 do    (loop for alpha from 0.2 to 0.6 by 0.01 do      (push (list f lambda alpha (mean (rest (funcall f alpha lambda)))) data))))(loop for f in '(learning-curve-true-online learning-curve-TDlambda learning-curve-dutch-TDlambda learning-curve-lambda-return) do(loop for i below 5   for e in (sort (remove-if-not (lambda (x) (eq (first x) f)) data) #'< :key #'fourth)  do (print e)))(setup 100 10)(online-nstep)     1st edition, Figure 7.2, upper graph(online-TDlambda)  1st edition, Figure 7.9(online-lambda-return)(true-online-TDlambda)(dutch-TDlambda)(compare-algs)(graph (learning-curve-TDlambda 0.9 0)|#